{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_wg_2_KoBERT Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOStIHMiRzWQlz/sx++2aR/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf02bbd0ee754efd92d9f748fb1d6555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af3b142b31344d5cbd2ad230df38b264",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6098edecd07344cabc2ffe3c8757ec47",
              "IPY_MODEL_cabe60de41ee453ba37e715c1fcf69ff"
            ]
          }
        },
        "af3b142b31344d5cbd2ad230df38b264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6098edecd07344cabc2ffe3c8757ec47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aece3bcfcedb4f11bdfec1a6005cf460",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea3b84dfba6b4b5c96839075b63a775a"
          }
        },
        "cabe60de41ee453ba37e715c1fcf69ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2428d3b6c9fc4429a5a0b2b8eb06f88e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 3.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b6c3527608c4c93a6e461f17465d88b"
          }
        },
        "aece3bcfcedb4f11bdfec1a6005cf460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea3b84dfba6b4b5c96839075b63a775a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2428d3b6c9fc4429a5a0b2b8eb06f88e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b6c3527608c4c93a6e461f17465d88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e246a9aed7b4e189ec9339cd4f5868e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c520f0a1a28442baf15b26722e2ada1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d82f22935c794cd2ad3136532fa5bd9e",
              "IPY_MODEL_06ad7f552b2249c3bc1ab2510fc1cbcd"
            ]
          }
        },
        "2c520f0a1a28442baf15b26722e2ada1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d82f22935c794cd2ad3136532fa5bd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3f311ae5d2b45be8b50f28f5f3a91a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e256c001f7e04921a1ad43d8e3de5e4a"
          }
        },
        "06ad7f552b2249c3bc1ab2510fc1cbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64e0b1271089461983759d1d778aa199",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 371k/371k [00:10&lt;00:00, 33.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee8ad7a2112d45a8b649bc94379b5952"
          }
        },
        "c3f311ae5d2b45be8b50f28f5f3a91a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e256c001f7e04921a1ad43d8e3de5e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64e0b1271089461983759d1d778aa199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee8ad7a2112d45a8b649bc94379b5952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3882b70cd8a94db5af957e8a83328b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92848b4e98ca4b25aa29dbf8ef889e38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6cc30cb77a334b538be35198751acd97",
              "IPY_MODEL_197b61196533480483e0d35acd05cfee"
            ]
          }
        },
        "92848b4e98ca4b25aa29dbf8ef889e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cc30cb77a334b538be35198751acd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b74e924be8e64910a17cdb8cd2198ca5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f8859a53a1242e999bd81eeb9bf9d48"
          }
        },
        "197b61196533480483e0d35acd05cfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab761c1dfde04443af9f033f3840fda0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:10&lt;00:00, 7.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_980fdc06b40d44b18fd8337d94a103f7"
          }
        },
        "b74e924be8e64910a17cdb8cd2198ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f8859a53a1242e999bd81eeb9bf9d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab761c1dfde04443af9f033f3840fda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "980fdc06b40d44b18fd8337d94a103f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guard1000/SKT_AI_WG/blob/master/2021_wg_2_KoBERT_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPWtC7wNIEf0"
      },
      "source": [
        "# 본 자료는 kimwoonggon님 제작한 publicservant_AI의 Tutorial 3개를 조합해 재구성하였습니다.\r\n",
        "# 버트모형 직접 사용해보기 Tutorial Study 자료입니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g3VM2jeodCs"
      },
      "source": [
        "# Huggingface 소개\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/6DM516z.png)  \n",
        "![대체 텍스트](https://i.imgur.com/g6R67h4.png)    \n",
        "https://huggingface.co/transformers/ \n",
        "\n",
        "HuggingFace는 자연어 처리 인공지능 모델에서, BERT 모델 같은 트랜스포머 모델들을 쉽게 다룰 수 있게 해주는 패키지입니다.  \n",
        "기본적으로 pytorch 기반으로 만들어져 있지만, 텐서플로우 2.0에서도 본 패키지를 사용 가능합니다.  \n",
        "텐서플로우 2.0은 기존 케라스를 포함하고 있기 때문에, 기존 텐서플로우나 케라스에 익숙하신 분들이 쉽게 사용할 수 있습니다.  \n",
        "텐서플로우 2.0 기반의 huggingface 사용 방법을 네이버 영화 긍부정 분석을 실습하면서 배워 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJQNSq3Rmnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LeBONl3Rt6J"
      },
      "source": [
        "<h2><strong> 1. 버트 모형 소개 </strong></h2>\n",
        "<p> 버트 모형은 2018년 11월 구글이 공개한 인공지능(AI) 언어 모델로써 기존 자연어 모델의 성능을 가볍게 뛰어넘었으며, 일부 성능 평가에서는 인간보다 더 높은 성능을 기록한 모델입니다. <strong>BERT는 Bidirectional Encoder Representations from Transformers</strong>의 약자로 18년 10월 구글에 의해 논문이 공개되었습니다.<br>\n",
        "버트 모형의 특징은 <strong>사전학습, 문맥학습, 파인튜닝</strong>을 들 수 있습니다.<br>\n",
        "<br><strong>(사전학습)</strong> 위키피디아 같은 아주 큰 데이터들을 사용하여 '언어 이해' 모델을 사전학습(Pre-training)한다. 광범위한 데이터로 인간이 살아오면서 체득한 지식과 같이 다양한 데이터를 학습하게 됩니다.<br>\n",
        "<strong>(문맥학습1)</strong> 문장 순서를 학습하여 다음에 나온 문장이 순서에 맞는 문장인지 학습합니다.<br><br>&nbsp;&nbsp;=>  문장1: 저 남자는 회사에 출근했다<br>&nbsp;&nbsp;=>  문장2: 회사에 출근하자마자 저 남자는 커피를 끓여 마셨다.<strong>    (순서가 맞음)</strong><br><br>&nbsp;&nbsp;=> 문장3: 저 여자는 퇴근하려 한다.<br>&nbsp;&nbsp;=> 문장4: 강아지는 예쁘다.<strong>    (순서가 틀린 문장)</strong><br><br><strong>(문맥학습2)</strong> 양방향으로 학습하여 가려진 단어를 맞춘다.<br>&nbsp;&nbsp;&nbsp;&nbsp;문장 : 저 남자는 (①)에 출근했다. 회사에 출근하자마자 저 남자는 (②)를 마셨다.<br>&nbsp;&nbsp;=> ① : 회사 ② : 커피<br><br><strong>(파인튜닝)</strong> 이미 사람처럼 광범위한 글을 학습한 인공지능을 기반으로 하여 새로운 과제를 해결하게 됩니다. 이미 기반 지식이 있기 때문에 새로운 것을 쉽고 빠르게 학습할 수 있습니다.<br>\n",
        "본 실습에서는 네이버 영화 평가 댓글로 긍정 부정인지를 예측하는 버트 모형을 생성해 보겠습니다.</p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhODHE2XhI2j"
      },
      "source": [
        "<h2><strong>2. 버트라는 도구를 활용하여 네이버 영화 평가 댓글 긍정 부정 예측하기</strong></h2>\n",
        "\n",
        "<p> 버트라는 모형에 영화를 평가하는 댓글을 인풋으로 넣으면 평가가 긍정인지 부정인지를 예측하게 됩니다. 긍정에 가까우면 1을, 부정에 가까우면 0을 출력하게 됩니다.<br>\n",
        "함수로 표현하면 버트 모형 함수 <strong>function(영화댓글) = 1 or 0</strong>입니다.<br>\n",
        "그림으로 살펴보도록 하겠습니다.</p>\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/YmdAqbT.png)\n",
        "\n",
        "<p> 네이버 영화 감성분석을 위해 파일을 불러왔습니다. 긍정은 1, 부정은 0으로 라벨링 되어 있습니다. 이 데이터를 활용하여 댓글을 인풋으로 넣으면 긍정인지 부정인지 예측하는 값을 예측하는 인공지능 모형을 생성합니다.<br> 본 실습에서는 광범위한 데이터로 사전 훈련된 인공지능 모형을 네이버 영화 감성 분석 데이터로 파인튜닝(추가학습)하여 아래 그림과 같은 긍정 부정을 예측하는 모형을 만들고자 합니다.</p>\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/zNXVb3G.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44p5dGlxT4tH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY0oR4s7scKf"
      },
      "source": [
        "#목차\n",
        "이번 실습은 <b>1) 네이버 감성분석 데이터 불러오기 및 전처리 2) BERT 인풋 만들기 3) 버트를 활용한 감성분석 모델 만들기 4) 훈련 및 성능 검증 5) 실제 데이터로 실습하기</b>로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6x9xBzrT8mJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcxkFoFEulHa"
      },
      "source": [
        "#BERT를 활용하여 네이버 감성분석 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_X3MbBns6fL"
      },
      "source": [
        "## 네이버 감성분석 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3MDrbfpfxV"
      },
      "source": [
        "huggingface 패키지를 Colab에 설치합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ngwrp9rUELD",
        "outputId": "d400ff43-4fa7-4c57-94d9-9b723d989d5e"
      },
      "source": [
        "!pip install transformers\r\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 18.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=afc4eb3fa1b151796f6ff4be59e72637e2212c4b4f320c7391213aec8068529b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 5.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAaQpYp8UFM3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from transformers import *\r\n",
        "import json\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from tqdm import tqdm\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgUYFux4rPVC"
      },
      "source": [
        "이번 예제에서 사용할 네이버 영화 감상분석 데이터를 다운로드 합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC7Kh77KUeB8",
        "outputId": "078511dd-067a-457f-aebf-783f22b3bf6f"
      },
      "source": [
        "# 네이버 영화 감성분석 데이터 다운로드\r\n",
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 18.63 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw0XD4LRUfJm",
        "outputId": "cbee0a4d-7a80-4845-e340-5411e8bbd9e8"
      },
      "source": [
        "os.listdir('nsmc')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['synopses.json',\n",
              " 'ratings_train.txt',\n",
              " '.git',\n",
              " 'raw',\n",
              " 'ratings_test.txt',\n",
              " 'README.md',\n",
              " 'code',\n",
              " 'ratings.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JFTyGGxwIwI"
      },
      "source": [
        "딥러닝 훈련에 사용 할 train 데이터와 test 데이터를 pandas dataframe 형식으로 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XeWU_2OsRJ3"
      },
      "source": [
        "train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n",
        "test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGJpPdIBsVKx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "952b6e46-49cb-47cf-a44a-4c848243716f"
      },
      "source": [
        "train[50:70]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>9063648</td>\n",
              "      <td>영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>8272095</td>\n",
              "      <td>야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>2345905</td>\n",
              "      <td>이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>7865630</td>\n",
              "      <td>난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>7207064</td>\n",
              "      <td>재미있어요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>5719655</td>\n",
              "      <td>전 좋아요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1651126</td>\n",
              "      <td>최고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>7246040</td>\n",
              "      <td>너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>717775</td>\n",
              "      <td>심심한영화.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>8317483</td>\n",
              "      <td>백봉기 언제나오나요?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1031725</td>\n",
              "      <td>보는내내 그대로 들어맞는 예측 카리스마 없는 악역</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>3993146</td>\n",
              "      <td>불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>2196616</td>\n",
              "      <td>평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>8203798</td>\n",
              "      <td>보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>2332588</td>\n",
              "      <td>사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>10084753</td>\n",
              "      <td>많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>8518645</td>\n",
              "      <td>예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>7956793</td>\n",
              "      <td>김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>3996917</td>\n",
              "      <td>재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>8128006</td>\n",
              "      <td>노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                           document  label\n",
              "50   9063648  영화가 사람의 영혼을 어루만져 줄 수도 있군요 거친 세상사를 잠시 잊고 동화같은 영...      1\n",
              "51   8272095              야 세르게이! 작은고추의 매운맛을 보여주마! 포퐁저그 콩진호가 간다      0\n",
              "52   2345905                   이렇게 가슴시리게 본 드라마가 또 있을까? 감동 그 자체!      1\n",
              "53   7865630  난또 저 꼬마애가 무슨 원한이 깊길래.,. 했더니 OO 그냥 혼자 나대다 OO걸 어...      0\n",
              "54   7207064                                              재미있어요      1\n",
              "55   5719655                                              전 좋아요      1\n",
              "56   1651126                                                 최고      0\n",
              "57   7246040  너무 충격적이엇다. 기분을 완전히 푹 꺼지게 하는 느낌... 활력이라고는 하나도 없...      1\n",
              "58    717775                                             심심한영화.      0\n",
              "59   8317483                                        백봉기 언제나오나요?      1\n",
              "60   1031725                        보는내내 그대로 들어맞는 예측 카리스마 없는 악역      0\n",
              "61   3993146                    불알이 나와서 당황...아무튼 영화가 중간에 끝나는 느낌      0\n",
              "62   2196616                       평범함속에 녹아든 평범한 일상. 조금 밋밋한게 흠.      0\n",
              "63   8203798  보던거라 계속보고있는데 전개도 느리고 주인공인 은희는 한두컷 나오면서 소극적인모습에...      0\n",
              "64   2332588                     사랑하고싶게하는,가슴속온감정을헤집어놓는영화예요정말최고.      1\n",
              "65  10084753  많은 사람들이 이 다큐를 보고 우리나라 슬픈 현대사의 한 단면에 대해 깊이 생각하고...      1\n",
              "66   8518645  예전 작품 캐릭터, 에피소드 재탕 삼탕 사골우려먹듯 우리고 내용은 산으로 가고 시청...      0\n",
              "67   7956793           김남길의 백점짜리 연기력과 초반 몰입도에도 불구하고 지루하고 손예진 ㅈㅈ      0\n",
              "68   3996917                       재밌네 비슷한 영화를 안보신 분들한테는 재미있을 듯      1\n",
              "69   8128006                 노래실력으로뽑는게 맞냐? 박시환이 mama나가면 진짜 망신이다      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1h3X_7tHpy"
      },
      "source": [
        "## 버트 인풋 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4JGys9DrU4_"
      },
      "source": [
        "한글 데이터를 분석하려면, 100개가 넘는 언어에 대해 훈련된 버트를 사용해야 합니다.  \n",
        "multilingual BERT를 사용한다고 하면, 토크나이저를 다음과 같이 huggingface로 아주 쉽게 토크나이저를 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Xgl9RtsGul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "bf02bbd0ee754efd92d9f748fb1d6555",
            "af3b142b31344d5cbd2ad230df38b264",
            "6098edecd07344cabc2ffe3c8757ec47",
            "cabe60de41ee453ba37e715c1fcf69ff",
            "aece3bcfcedb4f11bdfec1a6005cf460",
            "ea3b84dfba6b4b5c96839075b63a775a",
            "2428d3b6c9fc4429a5a0b2b8eb06f88e",
            "0b6c3527608c4c93a6e461f17465d88b"
          ]
        },
        "outputId": "e270bde3-0dad-4d0d-cec6-0f601cf644c4"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf02bbd0ee754efd92d9f748fb1d6555",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii2W5UbyuN2b"
      },
      "source": [
        "버트를 사용하기에 앞서 가장 기초에 속하는 tokenizer 사용 방법에 대해서 잠시 배워보도록 하겠습니다.  \n",
        "tokenizer.encode => 문장을 버트 모델의 인풋 토큰값으로 바꿔줌  \n",
        "tokenizer.tokenize => 문장을 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybf2-OluWro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0be4cb-31c0-41d6-db93-2d25d6cddb4d"
      },
      "source": [
        "print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 9356, 11018, 31605, 31605, 110589, 71568, 118913, 11018, 9576, 119281, 9786, 79940, 23811, 40364, 9520, 23160, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CshMEDzEcvdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b5a414-ee05-40de-88c3-5bc467e88658"
      },
      "source": [
        "print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['보', '##는', '##내', '##내', '그대로', '들어', '##맞', '##는', '예', '##측', '카', '##리스', '##마', '없는', '악', '##역']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2nQ1cVlg3CU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8mj0LtwhD9L"
      },
      "source": [
        "만약 KoBERT를 활용하고자 한다면...  \n",
        "\n",
        "\n",
        "이번에는 한국어 데이터로 훈련되었고, SKT에서 만든 KoBERT를 사용하도록 하겠습니다.  \n",
        "모델을 로드하기에 앞서, 토크나이저를 불러오도록 하겠습니다.  \n",
        "huggingface에서는 아주 쉽게 토크나이저를 불러올 수 있습니다.  \n",
        "https://github.com/monologg/KoBERT-NER 에서 kobert를 tokenize 할 수 있는 코드를 가져왔습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "4e246a9aed7b4e189ec9339cd4f5868e",
            "2c520f0a1a28442baf15b26722e2ada1",
            "d82f22935c794cd2ad3136532fa5bd9e",
            "06ad7f552b2249c3bc1ab2510fc1cbcd",
            "c3f311ae5d2b45be8b50f28f5f3a91a1",
            "e256c001f7e04921a1ad43d8e3de5e4a",
            "64e0b1271089461983759d1d778aa199",
            "ee8ad7a2112d45a8b649bc94379b5952",
            "3882b70cd8a94db5af957e8a83328b15",
            "92848b4e98ca4b25aa29dbf8ef889e38",
            "6cc30cb77a334b538be35198751acd97",
            "197b61196533480483e0d35acd05cfee",
            "b74e924be8e64910a17cdb8cd2198ca5",
            "0f8859a53a1242e999bd81eeb9bf9d48",
            "ab761c1dfde04443af9f033f3840fda0",
            "980fdc06b40d44b18fd8337d94a103f7"
          ]
        },
        "id": "5UHtTEU-g3Md",
        "outputId": "29bae339-a35b-4c7b-aec4-d0319cb2d22f"
      },
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "import unicodedata\r\n",
        "from shutil import copyfile\r\n",
        "\r\n",
        "from transformers import PreTrainedTokenizer\r\n",
        "\r\n",
        "\r\n",
        "logger = logging.getLogger(__name__)\r\n",
        "\r\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\r\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\r\n",
        "\r\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\r\n",
        "    \"vocab_file\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\r\n",
        "    },\r\n",
        "    \"vocab_txt\": {\r\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\r\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\r\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\r\n",
        "    \"monologg/kobert\": 512,\r\n",
        "    \"monologg/kobert-lm\": 512,\r\n",
        "    \"monologg/distilkobert\": 512\r\n",
        "}\r\n",
        "\r\n",
        "PRETRAINED_INIT_CONFIGURATION = {\r\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\r\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\r\n",
        "}\r\n",
        "\r\n",
        "SPIECE_UNDERLINE = u'▁'\r\n",
        "\r\n",
        "\r\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\r\n",
        "    \"\"\"\r\n",
        "        SentencePiece based tokenizer. Peculiarities:\r\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\r\n",
        "    \"\"\"\r\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\r\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\r\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\r\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\r\n",
        "\r\n",
        "    def __init__(\r\n",
        "            self,\r\n",
        "            vocab_file,\r\n",
        "            vocab_txt,\r\n",
        "            do_lower_case=False,\r\n",
        "            remove_space=True,\r\n",
        "            keep_accents=False,\r\n",
        "            unk_token=\"[UNK]\",\r\n",
        "            sep_token=\"[SEP]\",\r\n",
        "            pad_token=\"[PAD]\",\r\n",
        "            cls_token=\"[CLS]\",\r\n",
        "            mask_token=\"[MASK]\",\r\n",
        "            **kwargs):\r\n",
        "        super().__init__(\r\n",
        "            unk_token=unk_token,\r\n",
        "            sep_token=sep_token,\r\n",
        "            pad_token=pad_token,\r\n",
        "            cls_token=cls_token,\r\n",
        "            mask_token=mask_token,\r\n",
        "            **kwargs\r\n",
        "        )\r\n",
        "\r\n",
        "        # Build vocab\r\n",
        "        self.token2idx = dict()\r\n",
        "        self.idx2token = []\r\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\r\n",
        "            for idx, token in enumerate(f):\r\n",
        "                token = token.strip()\r\n",
        "                self.token2idx[token] = idx\r\n",
        "                self.idx2token.append(token)\r\n",
        "\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "\r\n",
        "        self.do_lower_case = do_lower_case\r\n",
        "        self.remove_space = remove_space\r\n",
        "        self.keep_accents = keep_accents\r\n",
        "        self.vocab_file = vocab_file\r\n",
        "        self.vocab_txt = vocab_txt\r\n",
        "\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(vocab_file)\r\n",
        "\r\n",
        "    @property\r\n",
        "    def vocab_size(self):\r\n",
        "        return len(self.idx2token)\r\n",
        "\r\n",
        "    def __getstate__(self):\r\n",
        "        state = self.__dict__.copy()\r\n",
        "        state[\"sp_model\"] = None\r\n",
        "        return state\r\n",
        "\r\n",
        "    def __setstate__(self, d):\r\n",
        "        self.__dict__ = d\r\n",
        "        try:\r\n",
        "            import sentencepiece as spm\r\n",
        "        except ImportError:\r\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\r\n",
        "                           \"pip install sentencepiece\")\r\n",
        "        self.sp_model = spm.SentencePieceProcessor()\r\n",
        "        self.sp_model.Load(self.vocab_file)\r\n",
        "\r\n",
        "    def preprocess_text(self, inputs):\r\n",
        "        if self.remove_space:\r\n",
        "            outputs = \" \".join(inputs.strip().split())\r\n",
        "        else:\r\n",
        "            outputs = inputs\r\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\r\n",
        "\r\n",
        "        if not self.keep_accents:\r\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\r\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\r\n",
        "        if self.do_lower_case:\r\n",
        "            outputs = outputs.lower()\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\r\n",
        "        \"\"\" Tokenize a string. \"\"\"\r\n",
        "        text = self.preprocess_text(text)\r\n",
        "\r\n",
        "        if not sample:\r\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\r\n",
        "        else:\r\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\r\n",
        "        new_pieces = []\r\n",
        "        for piece in pieces:\r\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\r\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\r\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\r\n",
        "                    if len(cur_pieces[0]) == 1:\r\n",
        "                        cur_pieces = cur_pieces[1:]\r\n",
        "                    else:\r\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\r\n",
        "                cur_pieces.append(piece[-1])\r\n",
        "                new_pieces.extend(cur_pieces)\r\n",
        "            else:\r\n",
        "                new_pieces.append(piece)\r\n",
        "\r\n",
        "        return new_pieces\r\n",
        "\r\n",
        "    def _convert_token_to_id(self, token):\r\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\r\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\r\n",
        "\r\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\r\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\r\n",
        "        return self.idx2token[index]\r\n",
        "\r\n",
        "    def convert_tokens_to_string(self, tokens):\r\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\r\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\r\n",
        "        return out_string\r\n",
        "\r\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\r\n",
        "        by concatenating and adding special tokens.\r\n",
        "        A RoBERTa sequence has the following format:\r\n",
        "            single sequence: [CLS] X [SEP]\r\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\r\n",
        "        \"\"\"\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\r\n",
        "\r\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\r\n",
        "        \"\"\"\r\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\r\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\r\n",
        "        Args:\r\n",
        "            token_ids_0: list of ids (must not contain special tokens)\r\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\r\n",
        "                for sequence pairs\r\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\r\n",
        "                special tokens for the model\r\n",
        "        Returns:\r\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if already_has_special_tokens:\r\n",
        "            if token_ids_1 is not None:\r\n",
        "                raise ValueError(\r\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\r\n",
        "                    \"ids is already formated with special tokens for the model.\"\r\n",
        "                )\r\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\r\n",
        "\r\n",
        "        if token_ids_1 is not None:\r\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\r\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\r\n",
        "\r\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\r\n",
        "        \"\"\"\r\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\r\n",
        "        A BERT sequence pair mask has the following format:\r\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\r\n",
        "        | first sequence    | second sequence\r\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\r\n",
        "        \"\"\"\r\n",
        "        sep = [self.sep_token_id]\r\n",
        "        cls = [self.cls_token_id]\r\n",
        "        if token_ids_1 is None:\r\n",
        "            return len(cls + token_ids_0 + sep) * [0]\r\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\r\n",
        "\r\n",
        "    def save_vocabulary(self, save_directory):\r\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\r\n",
        "            to a directory.\r\n",
        "        \"\"\"\r\n",
        "        if not os.path.isdir(save_directory):\r\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\r\n",
        "            return\r\n",
        "\r\n",
        "        # 1. Save sentencepiece model\r\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\r\n",
        "\r\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\r\n",
        "            copyfile(self.vocab_file, out_vocab_model)\r\n",
        "\r\n",
        "        # 2. Save vocab.txt\r\n",
        "        index = 0\r\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\r\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\r\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\r\n",
        "                if index != token_index:\r\n",
        "                    logger.warning(\r\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\r\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\r\n",
        "                    )\r\n",
        "                    index = token_index\r\n",
        "                writer.write(token + \"\\n\")\r\n",
        "                index += 1\r\n",
        "\r\n",
        "        return out_vocab_model, out_vocab_txt\r\n",
        "\r\n",
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e246a9aed7b4e189ec9339cd4f5868e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3882b70cd8a94db5af957e8a83328b15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D01eISXVhQyH"
      },
      "source": [
        "# kobert 토크나이저 import\r\n",
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUDUv0Z-hRaS",
        "outputId": "5624a672-ecbc-4f81-aa94-9f11fb66f658"
      },
      "source": [
        "print(tokenizer.encode(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 2366, 5678, 5678, 1192, 1804, 6166, 5760, 3415, 4638, 3272, 3133, 6926, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heaZtKMAiZXc",
        "outputId": "40bdf40d-df62-4910-cae8-31961d4f3e0b"
      },
      "source": [
        "print(tokenizer.tokenize(\"보는내내 그대로 들어맞는 예측 카리스마 없는 악역\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁보는', '내', '내', '▁그대로', '▁들어', '맞', '는', '▁예측', '▁카리스마', '▁없는', '▁악', '역']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4W2_F51ia93"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9sFKLjD-v2n"
      },
      "source": [
        "**버트 논문에 따르면, 모형에 들어갈 인풋은 토큰, 세그먼트, 포지션으로 구성됩니다.**  \n",
        "버트에 인풋으로 들어가는 토큰은 문장을 토크나이징 한 후, 인덱스 번호를 매긴 것입니다.  \n",
        "세그먼트는 예를 들어 문장이 두 개가 있다면, 앞의 문장과 뒤의 문장을 구분하는 것입니다.  \n",
        "포지션 임베딩은 단순히 단어의 위치를 말하며 단어 순서에 따라서 자동으로 부여됩니다.\n",
        "\n",
        "토큰, 세그먼트, 포지션을 인풋으로 버트 모형에 넣으면 기하학적인 문장 공간으로 임베딩이 됩니다.\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/l9BTao3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORJ-Eq61u2V1"
      },
      "source": [
        "우리가 네이버 영화 평가 긍부정 분석을 위해, train 15만개의 데이터를 버트의 인풋 값으로 바꿔주겠습니다.  \n",
        "\n",
        "\n",
        "버트의 인풋은 토큰, 세그멘트, 마스크로 나눠집니다.  \n",
        "이 세 값이 버트 모형에 들어가서, 버트 모형에 맞게 고차원으로 임베딩이 되게 되는 원리입니다.  \n",
        "\n",
        "1) 토큰은 말 그대로 단어를 단어사전의 위치값으로 표현해주는 것이며,\n",
        "\n",
        "2) 세그멘트는 버트 모형에서 문장이 앞 문장인지, 뒷 문장인지 표현해주는 것입니다.(본 예제는 인풋으로 문장이 하나만 들어가므로 0으로 통일)  \n",
        "\n",
        "3) 마스크는 문장이 유효한 값인지, 아니면 유효하지 않은 값이라 패딩 값으로 채운 것인지를 나타냅니다.  \n",
        "문장이 유효한 값이면 1로 채우고, 유효하지 않은 값이면 0으로 채우게 됩니다. 이처럼 어텐션 마스크를 주면 패딩부분에 대해선 어텐션을 수행하지 않아 속도가 향상됩니다.\n",
        "\n",
        "문장마다 문장 길이는 다르지만, 버트의 인풋 길이는 일정해야 하므로, 버트에서 지정한 문장 길이를 초과하면 패딩값인 0을 채우게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bWdpfQmjeK1",
        "outputId": "cc9a27ac-b7f7-4229-ae8e-882caab662f8"
      },
      "source": [
        "print(tokenizer.tokenize(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁전', '율을', '▁일으키', '는', '▁영화', '.', '▁다시', '▁보고', '싶', '은', '▁영화']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc7SJBHGjhEn",
        "outputId": "af4cd2af-54d3-4b55-cb7f-24edf6ca15d3"
      },
      "source": [
        "print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYw0Lu_VjhG_",
        "outputId": "73d51c01-1b81-4f02-9b6c-51a5439b4eef"
      },
      "source": [
        "print(tokenizer.encode(\"전율을 일으키는 영화. 다시 보고싶은 영화\", max_length=64, pad_to_max_length=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr-l7XNcwtQB"
      },
      "source": [
        "토큰 인풋의 예를 들면 다음과 같습니다.  \n",
        "\n",
        "문장을 토크나이징 하면 \"전율을 일으키는 영화. 다시 보고싶은 영화\"가 \n",
        "\n",
        "**-> \"['▁전', '율을', '▁일으키', '는', '▁영화', '.', '▁다시', '▁보고', '싶', '은', '▁영화']** 로 토크나이징이 됩니다.  \n",
        "\n",
        "\n",
        "이거를 버트 인풋에 들어갈 숫자로 바꿔주면,  \n",
        "\n",
        "***-> [2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3]***\n",
        "\n",
        "로 바뀌게 됩니다. 여기 나오는 숫자들이 버트 인풋에 들어가는 토큰 인풋입니다.  \n",
        "\n",
        "버트 모형에 들어가는 인풋은 사실 일정한 길이를 가져야 합니다.(본 예제에서는 64)  \n",
        "따라서 남는 부분은 0으로 채워지게 됩니다(패딩)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUstk_vYdjni",
        "outputId": "8a687f73-dc23-4f51-86fa-d93e5daa342d"
      },
      "source": [
        "# 세그멘트 인풋\r\n",
        "print([0]*64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQxClepBx5aB"
      },
      "source": [
        "세그멘트 인풋은 문장이 앞문장인지 뒷문장인지 구분해주는 역할을 하는데요  \n",
        "본 예시에서는 문장 하나만 인풋으로 들어가기 때문에 0만 들어가게 되고, 문장 길이만큼의 0이 인풋으로 들어가게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVMZxMmjbvo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wEKq5qfxH9t"
      },
      "source": [
        "***종합하면***,  \n",
        "버트의 인풋은 토큰, 세그먼트, 마스크로 이루어져 있습니다.  \n",
        "\"전율을 일으키는 영화. 다시 보고싶은 영화\" 라는 문장을 가지고 예를 들면, 다음과 같습니다.\n",
        "\n",
        "토큰 인풋 : [2, 4012, 7071, 3815, 5760, 3394, 54, 1574, 2358, 6751, 7086, 3394, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "세그먼트 인풋 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "마스크 인풋 : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB6-AxBZkIhM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LYpgPArzjiI"
      },
      "source": [
        "네이버 영화 평가 문장들을 버트 인풋으로 바꿔보도록 하겠습니다.  \n",
        "문장이 토큰 인풋, 세그먼트 인풋, 마스크 인풋으로 변환 됩니다.  \n",
        "huggingface에서는 순서가 [토큰 인풋, 마스크 인풋, 세그먼트 인풋] 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcSb6G1BkKqT",
        "outputId": "9712758c-355d-4af5-de44-86c68546e4f0"
      },
      "source": [
        "def convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    \r\n",
        "    SEQ_LEN = 64 #SEQ_LEN : 버트에 들어갈 인풋의 길이\r\n",
        "    \r\n",
        "    tokens, masks, segments, targets = [], [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "        # token : 문장을 토큰화함\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\r\n",
        "       \r\n",
        "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        \r\n",
        "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\r\n",
        "        tokens.append(token)\r\n",
        "        masks.append(mask)\r\n",
        "        segments.append(segment)\r\n",
        "        \r\n",
        "        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\r\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\r\n",
        "\r\n",
        "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    targets = np.array(targets)\r\n",
        "\r\n",
        "    return [tokens, masks, segments], targets\r\n",
        "\r\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\r\n",
        "def load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\r\n",
        "    data_x, data_y = convert_data(data_df)\r\n",
        "    return data_x, data_y\r\n",
        "\r\n",
        "SEQ_LEN = 64\r\n",
        "BATCH_SIZE = 32\r\n",
        "# 긍부정 문장을 포함하고 있는 칼럼\r\n",
        "DATA_COLUMN = \"document\"\r\n",
        "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\r\n",
        "LABEL_COLUMN = \"label\"\r\n",
        "\r\n",
        "# train 데이터를 버트 인풋에 맞게 변환\r\n",
        "train_x, train_y = load_data(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/150000 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 150000/150000 [00:36<00:00, 4078.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEQjUWXjkSbX",
        "outputId": "e7bd7f0d-ebb9-45f1-ebb7-37c57f576539"
      },
      "source": [
        "# 훈련 성능을 검증한 test 데이터를 버트 인풋에 맞게 변환\r\n",
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2179: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 50000/50000 [00:11<00:00, 4317.82it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9PchwPpkfUM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45UY1wudwa3Q"
      },
      "source": [
        "## 버트를 활용한 감성분석 모델 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W85BlYfo2Wge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb313fb0-48e6-4d7b-9d3c-a99adc787017"
      },
      "source": [
        "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
        "\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDVZm4MVkuE9",
        "outputId": "5ce50e54-706d-4a71-c269-b19e7d80d2d4"
      },
      "source": [
        "bert_outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <KerasTensor: shape=(None, 64, 768) dtype=float32 (created by layer 'tf_bert_model_1')>),\n",
              "                              ('pooler_output',\n",
              "                               <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model_1')>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvEdyz1YlCJ7"
      },
      "source": [
        "# 1) last_hidden_state (torch.FloatTensor of shape (batch_size, sequence_length, hidden_size)) \r\n",
        "#    Sequence of hidden-states at the output of the last layer of the model.\r\n",
        "# 2) pooler_output (torch.FloatTensor of shape (batch_size, hidden_size)) \r\n",
        "#    Last layer hidden-state of the first token of the sequence (classification token) further processed by a Linear layer and a Tanh activation function. The Linear layer weights are trained from the next sentence prediction (classification) objective during pretraining\r\n",
        "#    -> contains a \"representation\" of each sequence! "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4NGKrt7fyq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol8pcd6pnSua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab531010-844d-496a-d87f-23ad968b9b4d"
      },
      "source": [
        "# 참고용) BERT 모형은 어떻게 생겼는가?\n",
        "# 구글 BERT 모형 load 후 model.summary() 로 확인한 모습은 아래와 같습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 128, 768), ( 91812096    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 128, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 128, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 128, 768)     98304       Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 128, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 128, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 128, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 128, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 128, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 128, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 128, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 128, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 128, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 128, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 128, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 128, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 128, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 128, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 128, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 128, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "MLM-Dense (Dense)               (None, 128, 768)     590592      Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Norm (LayerNormalization)   (None, 128, 768)     1536        MLM-Dense[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "Extract (Extract)               (None, 768)          0           Encoder-12-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MLM-Sim (EmbeddingSimilarity)   (None, 128, 119547)  119547      MLM-Norm[0][0]                   \n",
            "                                                                 Embedding-Token[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Masked (InputLayer)       (None, 128)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "NSP-Dense (Dense)               (None, 768)          590592      Extract[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "MLM (Masked)                    (None, 128, 119547)  0           MLM-Sim[0][0]                    \n",
            "                                                                 Input-Masked[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "NSP (Dense)                     (None, 2)            1538        NSP-Dense[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 178,271,741\n",
            "Trainable params: 178,271,741\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zLzn5gp7gHg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JyoENLjutFl"
      },
      "source": [
        "bert_outputs = bert_outputs[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt1AEYcOv2vI"
      },
      "source": [
        "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\r\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\r\n",
        "sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\r\n",
        "sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEWKThl4u0aT"
      },
      "source": [
        "# CF> Rectified Adam 옵티마이저 사용하고 싶으면 아래와 같이 정의 후 compile시 optimizer로 opt 넣어주면 됨!\r\n",
        "\r\n",
        "import tensorflow_addons as tfa\r\n",
        "# 총 batch size * 4 epoch = 2344 * 4 (SEQ_LEN이 64이므로, 2343*64=149952, 2344*64=150016 -> 따라서 batch_size = 2344)\r\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqrHYZT4xeLd",
        "outputId": "50f56bbd-06dd-483b-8895-2868773d2953"
      },
      "source": [
        "sentiment_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   TFBaseModelOutputWit 92186880    input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 768)          0           tf_bert_model_1[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            769         dropout_75[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 92,187,649\n",
            "Trainable params: 92,187,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FxdCHf6zjxh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axUBMRPWxyxP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exIMOc2Wy-7L"
      },
      "source": [
        "# TPU를 활용하고자 할 경우"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU1Iz24OxwyN"
      },
      "source": [
        "**TPU를 활용하려면 함수로 묶어야 합니다.**\r\n",
        "\r\n",
        "감정 분석에 맞는 버트 모형을 리턴하는 함수를 정의하도록 하겠습니다.\r\n",
        "\r\n",
        "***바로 위 셀들에서 수행한 것을 그대로 함수로 만드는 작업입니다.***\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7xB3sDAxf9m"
      },
      "source": [
        "def create_sentiment_bert():\r\n",
        "  # 버트 pretrained 모델 로드\r\n",
        "  model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\r\n",
        "  # 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\r\n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\r\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\r\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\r\n",
        "\r\n",
        "  # 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\r\n",
        "  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\r\n",
        "\r\n",
        "  bert_outputs = bert_outputs[1]\r\n",
        "  sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\r\n",
        "  sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\r\n",
        "  sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\r\n",
        "\r\n",
        "  sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\r\n",
        "  return sentiment_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAB8uGTCwdDq",
        "outputId": "49498b3b-8075-46be-c393-63dcb6d4a460"
      },
      "source": [
        "# TPU 객체 지정 - TPU 사용 안할 경우, 이 셀을 실행 안하면 됨. 주석처리\r\n",
        "TPU = True\r\n",
        "if TPU:\r\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "else:\r\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.49.239.66:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.49.239.66:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7Quxd91FzS",
        "outputId": "2abf932e-9680-4444-b3f3-3f1864f1dc45"
      },
      "source": [
        "# TPU 실행 시\r\n",
        "if TPU:\r\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n",
        "# 함수를 strategy.scope로 묶어 줌\r\n",
        "  with strategy.scope():\r\n",
        "    sentiment_model = create_sentiment_bert()\r\n",
        "  \r\n",
        "  sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=64, validation_data=(test_x, test_y))\r\n",
        "else:\r\n",
        "  # GPU 모드로 훈련시킬 때\r\n",
        "  sentiment_model = create_sentiment_bert()\r\n",
        "  \r\n",
        "  sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=64, validation_data=(test_x, test_y))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2344/2344 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.7031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2344/2344 [==============================] - 358s 109ms/step - loss: 0.5087 - accuracy: 0.7032 - val_loss: 0.3018 - val_accuracy: 0.8774\n",
            "Epoch 2/4\n",
            "2344/2344 [==============================] - 201s 86ms/step - loss: 0.2459 - accuracy: 0.8998 - val_loss: 0.2585 - val_accuracy: 0.8961\n",
            "Epoch 3/4\n",
            "2344/2344 [==============================] - 202s 86ms/step - loss: 0.1732 - accuracy: 0.9341 - val_loss: 0.2685 - val_accuracy: 0.8960\n",
            "Epoch 4/4\n",
            "2344/2344 [==============================] - 202s 86ms/step - loss: 0.1071 - accuracy: 0.9617 - val_loss: 0.3074 - val_accuracy: 0.8990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suSlGRQOyzJ1"
      },
      "source": [
        "# TPU로 돌리면 약 15분 소요\r\n",
        "# GPU로 돌리면 약 90분 소요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj2P1y2j3VOG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4zsbBPQ3VX1"
      },
      "source": [
        "# save the model 하려면 이런식으로\r\n",
        "path = \"gdrive/My Drive/abc/defg\"\r\n",
        "sentiment_model.save_weights(path+\"/모델이름.h5\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYGDszQ73VeB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiVMTIVM4VBI"
      },
      "source": [
        "훈련 모델의 예측 성능을 F1 SCORE 체크해보기\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFom8ONh3Voj"
      },
      "source": [
        "def predict_convert_data(data_df):\r\n",
        "    global tokenizer\r\n",
        "    tokens, masks, segments = [], [], []\r\n",
        "    \r\n",
        "    for i in tqdm(range(len(data_df))):\r\n",
        "\r\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, truncation=True, padding='max_length')\r\n",
        "        num_zeros = token.count(0)\r\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\r\n",
        "        segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "        tokens.append(token)\r\n",
        "        segments.append(segment)\r\n",
        "        masks.append(mask)\r\n",
        "\r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    return [tokens, masks, segments]\r\n",
        "\r\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\r\n",
        "def predict_load_data(pandas_dataframe):\r\n",
        "    data_df = pandas_dataframe\r\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\r\n",
        "    data_x = predict_convert_data(data_df)\r\n",
        "    return data_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNV7dFhb4XWC",
        "outputId": "44484947-504c-4d3f-f77e-75c2fe94dfe8"
      },
      "source": [
        "# test 데이터 예측하기\r\n",
        "test_set = predict_load_data(test)\r\n",
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:12<00:00, 4121.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[   2,  517, 5515, ...,    1,    1,    1],\n",
              "        [   2,  650,  278, ...,    1,    1,    1],\n",
              "        [   2, 2145, 6844, ...,    1,    1,    1],\n",
              "        ...,\n",
              "        [   2, 1212, 5859, ...,    1,    1,    1],\n",
              "        [   2, 4069, 2420, ...,    1,    1,    1],\n",
              "        [   2, 1914, 5760, ...,    1,    1,    1]]),\n",
              " array([[1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1],\n",
              "        [1, 1, 1, ..., 1, 1, 1]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kip9xGR41VR",
        "outputId": "5bc9ed04-9a06-4f35-e4aa-02d918c14f14"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  preds = sentiment_model.predict(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POgWwJD343wZ",
        "outputId": "084f87f6-7301-45ae-e7d6-a52b0f129c04"
      },
      "source": [
        "# 부정일수록 0, 긍정일수록 1 에 가깝게 결과 나옴\r\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9919911 ],\n",
              "       [0.97547936],\n",
              "       [0.97198397],\n",
              "       ...,\n",
              "       [0.35166603],\n",
              "       [0.00132734],\n",
              "       [0.00786406]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etlDV4XM5FSn"
      },
      "source": [
        "CF> 보편적으로 훈련한 모델을 F1 SCORE로 성능 측정\r\n",
        "\r\n",
        "\r\n",
        "F1 SCORE는 precision과 recall을 가중평균하여 계산합니다\r\n",
        "\r\n",
        "recall: (모델이 TRUE라고 판정한 것의 숫자)/(전체 TRUE의 숫자)\r\n",
        "\r\n",
        "precision : (진짜 TRUE) / (모델이 TRUE라고 판정한 것의 숫자)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ7bgJjo5T-e",
        "outputId": "8f14ae98-8756-40a4-fc4e-f52144c57a84"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "y_true = test['label']\r\n",
        "\r\n",
        "# F1 Score 확인\r\n",
        "print(classification_report(y_true, np.round(preds,0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90     24827\n",
            "           1       0.90      0.90      0.90     25173\n",
            "\n",
            "    accuracy                           0.90     50000\n",
            "   macro avg       0.90      0.90      0.90     50000\n",
            "weighted avg       0.90      0.90      0.90     50000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsuDBuVf5WkA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W2vCplv5oVD"
      },
      "source": [
        "# 실제 데이터를 예측시켜 보자!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wJZSSnx5vgh"
      },
      "source": [
        "# 입력받은 문장의 감정을 분류하는 함수를 만들어 보자.\r\n",
        "\r\n",
        "def sentence_convert_data(data):\r\n",
        "    global tokenizer\r\n",
        "    tokens, masks, segments = [], [], []\r\n",
        "    token = tokenizer.encode(data, max_length=SEQ_LEN, truncation=True, padding='max_length')\r\n",
        "    \r\n",
        "    num_zeros = token.count(0) \r\n",
        "    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \r\n",
        "    segment = [0]*SEQ_LEN\r\n",
        "\r\n",
        "    tokens.append(token)\r\n",
        "    segments.append(segment)\r\n",
        "    masks.append(mask)\r\n",
        "\r\n",
        "    tokens = np.array(tokens)\r\n",
        "    masks = np.array(masks)\r\n",
        "    segments = np.array(segments)\r\n",
        "    return [tokens, masks, segments]\r\n",
        "\r\n",
        "def movie_evaluation_predict(sentence):\r\n",
        "    data_x = sentence_convert_data(sentence)\r\n",
        "    predict = sentiment_model.predict(data_x)\r\n",
        "    predict_value = np.ravel(predict)\r\n",
        "    predict_answer = np.round(predict_value,0).item()\r\n",
        "    \r\n",
        "    if predict_answer == 0:\r\n",
        "      print(\"(부정 확률 : %.2f) 부정적인 영화 평가입니다.\" % (1-predict_value))\r\n",
        "    elif predict_answer == 1:\r\n",
        "      print(\"(긍정 확률 : %.2f) 긍정적인 영화 평가입니다.\" % predict_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I25K5v9g54EA",
        "outputId": "7ef062b7-8011-4770-8a67-0209e3d6352e"
      },
      "source": [
        "movie_evaluation_predict(\"영상미가 뛰어나구, 보면볼수록 가슴이 찡해지고 따뜻해지네요\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(긍정 확률 : 1.00) 긍정적인 영화 평가입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DKPm0Qh6Knu",
        "outputId": "9f414521-2a58-4dd7-8c40-e800dc8418c8"
      },
      "source": [
        "movie_evaluation_predict(\"어른들의 이야기 음악도 그렇고 풍경도 그렇고 영화의 색감도..\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(긍정 확률 : 0.99) 긍정적인 영화 평가입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn3IaiB36TBZ",
        "outputId": "1e71608f-b5df-4101-e761-b9a4f8415863"
      },
      "source": [
        "movie_evaluation_predict(\"2탄 나오면 안봄 차태현 연기못함 ㅋ\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(부정 확률 : 0.93) 부정적인 영화 평가입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usykk7O96drZ",
        "outputId": "3fb80adc-93ac-4974-c565-e4e782d37dae"
      },
      "source": [
        "movie_evaluation_predict(\"그냥저냥 10자까지 적을건 없음\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(부정 확률 : 0.58) 부정적인 영화 평가입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hahf4e3u6uN6",
        "outputId": "58fb8017-dc28-47c2-e185-c3c855c71d98"
      },
      "source": [
        "movie_evaluation_predict(\"이게 왜 1400만 찍은건지 이해가 안되는 영화2편은 별로 보고싶지가 않다\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(부정 확률 : 0.97) 부정적인 영화 평가입니다.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}